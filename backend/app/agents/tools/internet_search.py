import json
import logging

from app.agents.tools.agent_tool import AgentTool
from app.repositories.models.custom_bot import BotModel, InternetToolModel
from app.routes.schemas.conversation import type_model_name
from app.utils import get_bedrock_runtime_client
from duckduckgo_search import DDGS
from firecrawl import FirecrawlApp
from pydantic import BaseModel, Field, root_validator

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


class InternetSearchInput(BaseModel):
    query: str = Field(description="The query to search for on the internet.")
    locale: str = Field(
        default="en-us",
        description="The country code and language code for the search. Must be `{language}-{country}` for example `jp-jp` (Japanese - Japan), `zh-cn` (Chinese - China), `en-ca` (English - Canada), `fr-ca` (French - Canada), `en-nz` (English - New Zealand), etc. If empty the default is `en-us`.",
    )
    time_limit: str = Field(
        description="Retrieve only the most recent results, for example `1w` only returns the results from the last week. Units are 'd' (day), 'w' (week), 'm' (month), 'y' (year). Use empty string to retrieve all results."
    )

    @root_validator(pre=True)
    def validate_locale(cls, values):
        locale = values.get("locale")
        # Basic validation for locale format
        if not locale or locale.count("-") != 1:
            # Get the default value from the field definition
            default_locale = cls.__fields__["locale"].default
            values["locale"] = default_locale
        return values


def _summarize_content(content: str, title: str, url: str, query: str) -> str:
    """
    Summarize content using Claude 3 Haiku to prevent context window bloat.
    Returns a concise summary (500-800 tokens max) preserving key information.
    """
    try:
        client = get_bedrock_runtime_client()

        # Truncate content if it's too long to avoid token limits
        max_input_length = 8000  # Conservative limit for input
        if len(content) > max_input_length:
            content = content[:max_input_length] + "..."

        prompt = f"""Please provide a concise summary of the following web content in 500-800 tokens maximum. Focus on information that directly answers or relates to the user's query: "{query}"

Title: {title}
URL: {url}
Content: {content}

Summary:"""

        response = client.invoke_model(
            modelId="anthropic.claude-3-haiku-20240307-v1:0",
            contentType="application/json",
            accept="application/json",
            body=json.dumps(
                {
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 800,
                    "messages": [{"role": "user", "content": prompt}],
                }
            ),
        )

        response_body = json.loads(response["body"].read())
        summary = response_body["content"][0]["text"].strip()

        logger.info(
            f"Summarized content from {len(content)} chars to {len(summary)} chars"
        )
        return summary

    except Exception as e:
        logger.error(f"Error summarizing content: {e}")
        # Fallback: return truncated content if summarization fails
        fallback_content = content[:1000] + "..." if len(content) > 1000 else content
        logger.info(f"Using fallback content: {len(fallback_content)} chars")
        return fallback_content


def _search_with_duckduckgo(query: str, time_limit: str, locale: str) -> list:
    # Incoming locale expected as language-country (e.g. 'en-nz'). DDGS prefers country-language, so swap.
    language, country = locale.split("-", 1)
    REGION = f"{country}-{language}".lower()
    SAFE_SEARCH = "moderate"
    MAX_RESULTS = 20
    BACKEND = "api"
    logger.info(
        f"Executing DuckDuckGo search with query: {query}, region: {REGION}, time_limit: {time_limit}"
    )
    with DDGS() as ddgs:
        results = list(
            ddgs.text(
                keywords=query,
                region=REGION,
                safesearch=SAFE_SEARCH,
                timelimit=time_limit,
                max_results=MAX_RESULTS,
                backend=BACKEND,
            )
        )
        logger.info(f"DuckDuckGo search completed. Found {len(results)} results")

        # Summarize each result to prevent context bloat
        summarized_results = []
        for result in results:
            title = result["title"]
            url = result["href"]
            content = result["body"]

            # Summarize the content
            summary = _summarize_content(content, title, url, query)

            summarized_results.append(
                {
                    "content": summary,
                    "source_name": title,
                    "source_link": url,
                }
            )

        return summarized_results


def _search_with_firecrawl(
    query: str, api_key: str, locale: str, max_results: int = 10
) -> list:
    logger.info(
        f"Searching with Firecrawl. Query: {query}, Max Results: {max_results}, Locale: {locale}"
    )

    try:
        app = FirecrawlApp(api_key=api_key)

        # Search using Firecrawl
        # SearchParams: https://github.com/mendableai/firecrawl/blob/main/apps/python-sdk/firecrawl/firecrawl.py#L24
        from firecrawl import ScrapeOptions

        # Incoming locale is language-country (e.g. 'en-us').
        language, country = locale.split("-", 1)
        results = app.search(
            query,
            limit=max_results,
            lang=language,
            location=country,
            scrape_options=ScrapeOptions(formats=["markdown"], onlyMainContent=True),
        )

        if not results:
            logger.warning("No results found")
            return []

        # Log detailed information about the results object
        logger.info(
            f"results of firecrawl: success={getattr(results, 'success', 'unknown')} warning={getattr(results, 'warning', None)} error={getattr(results, 'error', None)}"
        )

        # Log the data structure
        if hasattr(results, "data"):
            data_sample = results.data[:1] if results.data else []
            logger.info(f"data sample: {data_sample}")
        else:
            logger.info(
                f"results attributes: {[attr for attr in dir(results) if not attr.startswith('_')]}"
            )
            logger.info(
                f"results as dict attempt: {dict(results) if hasattr(results, '__dict__') else 'no __dict__'}"
            )

        # Format and summarize search results
        search_results = []

        # Handle Firecrawl SearchResponse object structure
        # The Python SDK returns a SearchResponse object with .data attribute
        if hasattr(results, "data") and results.data:
            data_list = results.data
        else:
            logger.error(
                f"No data found in results. Results type: {type(results)}, attributes: {[attr for attr in dir(results) if not attr.startswith('_')]}"
            )
            return []

        logger.info(f"Found {len(data_list)} data items")
        for i, data in enumerate(data_list):
            try:
                logger.info(
                    f"Data item {i}: type={type(data)}, keys={list(data.keys()) if isinstance(data, dict) else 'not dict'}"
                )

                if isinstance(data, dict):
                    title = data.get("title", "")
                    # Try different URL fields based on Firecrawl API response structure
                    url = data.get("url", "") or (
                        data.get("metadata", {}).get("sourceURL", "")
                        if isinstance(data.get("metadata"), dict)
                        else ""
                    )
                    content = data.get("markdown", "") or data.get("content", "")

                    if not title and not content:
                        logger.warning(f"Skipping data item {i} - no title or content")
                        continue

                    # Summarize the content
                    summary = _summarize_content(content, title, url, query)

                    search_results.append(
                        {
                            "content": summary,
                            "source_name": title,
                            "source_link": url,
                        }
                    )
                else:
                    logger.warning(f"Data item {i} is not a dict: {type(data)}")
            except Exception as e:
                logger.error(f"Error processing data item {i}: {e}")
                continue

        logger.info(f"Found {len(search_results)} results from Firecrawl")
        return search_results

    except Exception as e:
        logger.error(f"Error searching with Firecrawl: {e}")
        logger.error(f"Exception type: {type(e)}")
        logger.error(f"Exception args: {e.args}")
        import traceback

        logger.error(f"Traceback: {traceback.format_exc()}")

        # Instead of raising, return empty list to allow fallback
        return []


def _internet_search(
    tool_input: InternetSearchInput, bot: BotModel | None, model: type_model_name | None
) -> list:
    query = tool_input.query
    time_limit = tool_input.time_limit
    locale = tool_input.locale

    logger.info(
        f"Internet search request - Query: {query}, Time Limit: {time_limit}, Locale: {locale}"
    )

    if bot is None:
        logger.warning("Bot is None, defaulting to DuckDuckGo search")
        return _search_with_duckduckgo(query, time_limit, locale)

    # Find internet search tool
    internet_tool = next(
        (tool for tool in bot.agent.tools if isinstance(tool, InternetToolModel)),
        None,
    )

    # If no internet tool found or search engine is duckduckgo, use DuckDuckGo
    if not internet_tool or internet_tool.search_engine == "duckduckgo":
        logger.info("No internet tool found or search engine is DuckDuckGo")
        return _search_with_duckduckgo(query, time_limit, locale)

    # Handle Firecrawl search
    if internet_tool.search_engine == "firecrawl":
        if not internet_tool.firecrawl_config:
            logger.error(
                "Firecrawl configuration is not set in the bot, falling back to DuckDuckGo"
            )
            return _search_with_duckduckgo(query, time_limit, locale)

        try:
            api_key = internet_tool.firecrawl_config.api_key
            if not api_key:
                logger.error("Firecrawl API key is empty, falling back to DuckDuckGo")
                return _search_with_duckduckgo(query, time_limit, locale)

            results = _search_with_firecrawl(
                query=query,
                api_key=api_key,
                locale=locale,
                max_results=internet_tool.firecrawl_config.max_results,
            )

            # If Firecrawl returns empty results, fallback to DuckDuckGo
            if not results:
                logger.warning(
                    "Firecrawl returned no results, falling back to DuckDuckGo"
                )
                return _search_with_duckduckgo(query, time_limit, locale)

            return results

        except Exception as e:
            logger.error(
                f"Error with Firecrawl search: {e}, falling back to DuckDuckGo"
            )
            return _search_with_duckduckgo(query, time_limit, locale)

    # Fallback to DuckDuckGo for any unexpected cases
    logger.warning("Unexpected search engine configuration, falling back to DuckDuckGo")
    return _search_with_duckduckgo(query, time_limit, locale)


internet_search_tool = AgentTool(
    name="internet_search",
    description="Search the internet for information.",
    args_schema=InternetSearchInput,
    function=_internet_search,
)
